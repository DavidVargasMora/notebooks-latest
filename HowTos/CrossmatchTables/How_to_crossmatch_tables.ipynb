{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to do an efficient crossmatch of a user table with a table in Data Lab\n",
    "\n",
    "In this notebook, we demonstrate how to do an efficient crossmatch of a user-provided table of data against a table hosted by Data Lab.  The basic steps are:\n",
    "\n",
    "* [Make sure that you are logged in as a registered user](#login)\n",
    "* [Upload your table into myDB, your personal database storage area](#import)\n",
    "* [Create and run a query to do the crossmatch using the q3c_join() function](#crossmatch)\n",
    "\n",
    "Click one of the links above if you want to jump to a section.\n",
    "\n",
    "*Revised: 09/24/18*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"login\"></a>\n",
    "### Standard Imports and Data Lab Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl import authClient as ac\n",
    "from dl import storeClient as sc\n",
    "from dl import queryClient as qc\n",
    "from dl.helpers.utils import convert        # to use Pandas\n",
    "import os, getpass\n",
    "\n",
    "do_cleanup = False                          # Remove any files/tables created by this notebook\n",
    "\n",
    "# Being logged in as a registered user is a necessary step since we will be using MyDB for storage.  \n",
    "# Once logged in, the token is stored on the server in the user's $HOME/.datalab directory.  \n",
    "# Passing the token to queryClient and storeClient is optional.\n",
    "\n",
    "# Check if logged in as user other than anonymous\n",
    "try:\n",
    "    user = ac.whoAmI()\n",
    "    if (user == 'anonymous'):\n",
    "        logged_in = False\n",
    "    else:\n",
    "        logged_in = True\n",
    "        token = ac.login(user) #Retrieve token (OPTIONAL)\n",
    "except:\n",
    "    logged_in = False\n",
    "\n",
    "# if not, prompt user to log in\n",
    "if (not logged_in):\n",
    "    try:\n",
    "        token = ac.login(input('Enter user name (+ENTER): '),getpass.getpass('Enter password (+ENTER): '))\n",
    "    except Exception as e:\n",
    "        print ('Error: ' + str(e))\n",
    "\n",
    "print('User: ' + ac.whoAmI())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of MyDB tables\n",
    "Let's start by getting a list of existing tables in MyDB. The way to list tables in your MyDB is with the *mydb_list()* method:\n",
    "\n",
    "        result = queryClient.mydb_list ([token], <table_name>)\n",
    "where\n",
    "\n",
    "        token         login token (optional)\n",
    "        table_name    name of the MyDB table to list (optional)\n",
    "        \n",
    "If no arguments are given, a list of all tables in the user MyDB is returned, one tablename per row.  If a table name is provided, the method returns a CSV string on column name and datatype, one column name per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Listing mydb tables:\\n\" + qc.mydb_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query database with output to mydb\n",
    "The most basic way to create a table in mydb is to issue a query against a table in the Data Lab database with output to mydb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select top 15 id,raj2000,dej2000 from usno.a2'\n",
    "try:\n",
    "    qc.query(adql=query, fmt='csv', out='mydb://usno_objects')\n",
    "except Exception as e:\n",
    "    print(e.message)\n",
    "\n",
    "print(\"Listing mydb tables:\\n\" + qc.mydb_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a user table\n",
    "But often a user will have an existing table that they wish to import into mydb.  The sections below show how to do this with a variety of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some sample data\n",
    "First, we'll create a table of data and store it locally as well put in VOSpace.  If you have a table on your local machine, you can use the Jupyter notebook's Upload feature to copy the table into Data Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = qc.query ('select id,raj2000 as ra,dej2000 as dec from usno.a2 limit 15')  # CSV String\n",
    "with open ('objects.csv','w') as fd:                                               # file of CSV data\n",
    "    fd.write (data)   \n",
    "df = convert(data)                                                                 # Pandas DataFrame\n",
    "tsv = data.replace(',','\\t')                                                       # Tab-separated\n",
    "asv = data.replace(',',' ')                                                        # ASCII-separated\n",
    "bsv = data.replace(',','|')                                                        # Bar-separated\n",
    "\n",
    "if sc.access ('vos://objects.csv'):\n",
    "    sc.rm ('vos://objects.csv')\n",
    "if sc.access ('vos://objects.vot'):\n",
    "    sc.rm ('vos://objects.vot')\n",
    "sc.put ('objects.csv', 'vos://objects.csv')                                        # Put a copy in VOSpace\n",
    "print(sc.ls ('objects.*', format='long', verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also have output the result of the query above directly to VOSpace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select top 15 id,raj2000,dej2000 from usno.a2'\n",
    "qc.query(adql=query, fmt='votable', out='vos://objects.vot') # FIXME - query save to existing file fails\n",
    "print(sc.ls ('objects.*', format='long', verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"import\"></a>\n",
    "### Import a Table Directly to MyDB\n",
    "The simplest way to import a table to your MyDB is with the *mydb_import()* method:\n",
    "\n",
    "        result = queryClient.mydb_import ([token], <table_name>, <data> [, schema=<schema_def>])\n",
    "where\n",
    "\n",
    "        token         login token (optional)\n",
    "        table_name    name of the MyDB table to create\n",
    "        data          filename of CSV data, a CSV string, or a Pandas DataFrame object\n",
    "        schema_def    [Optional, default=\"\"] The schema definition is stored in a text file or string. \n",
    "                      This is a CSV-formatted file that contains column name, (Postgres) data \n",
    "                      type, one row per column.\n",
    "        drop          [Optional, default=True] Drop any existing table before loading the new one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Import a (local) CSV file to a MyDB table called 'objects1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Local file result: '   + qc.mydb_import ('objects1', 'objects.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Import a CSV file from your Virtual Storage to a MyDB table called 'objects2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('VOS file result: '   + qc.mydb_import ('objects2', 'vos://objects.csv', verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3:  Import directly from a string containing CSV (or other delimited) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('String (CSV) result: ' + qc.mydb_import ('objects3', data))\n",
    "#print ('String (TSV) result: ' + qc.mydb_import ('objects3', data, delimiter='\\t'))\n",
    "#print ('String (ASV) result: ' + qc.mydb_import ('objects3', data, delimiter=' '))\n",
    "#print ('String (BSV) result: ' + qc.mydb_import ('objects3', data, delimiter='|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4: Import a Pandas DataFrame directly to a MyDB table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Pandas result: ' + qc.mydb_import ('objects4', df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 5:  Import CSV data, then append to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = qc.mydb_import ('objects5', data, verbose=True)             # Drop existing table by default\n",
    "print ('Num rows in objects5: ' + qc.query('select count(*) from mydb://objects5',fmt='csv'))\n",
    "\n",
    "res = qc.mydb_import ('objects5', data, verbose=True, drop=False) # Disable 'drop' to append\n",
    "print ('Num rows in objects5: ' + qc.query('select count(*) from mydb://objects5',fmt='csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 6:  Import a VOTable stored in Virtual Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a VOTable by calling the PanSTARRS Cone Search service.\n",
    "ps1_base_url = 'http://gsss.stsci.edu/webservices/vo/ConeSearch.aspx?CAT=PS1V3OBJECTS&'\n",
    "ps1_url = ps1_base_url + ('RA={0}&DEC={1}&SR={2}'.format(0.0,0.0,0.05))\n",
    "os.system ('wget -q -O ps1.vot \"' + ps1_url + '\"')\n",
    "\n",
    "# Put a copy in virtual storage.\n",
    "sc.put('ps1.vot',to='vos://ps1.vot')\n",
    "\n",
    "print (ps1_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the MyDB table directly from the VOTable on local disk, in VOSpace, and directly from the URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = qc.mydb_import ('objects6a', 'ps1.vot', verbose=True)             # Load from local VOTable\n",
    "print ('import res: ' + res)\n",
    "print ('Num rows in objects6a: ' + qc.query('select count(*) from mydb://objects6a',fmt='csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = qc.mydb_import ('objects6b', 'vos://ps1.vot', verbose=True)       # Load from virtual storage VOTable\n",
    "print ('Num rows in objects6b: ' + qc.query('select count(*) from mydb://objects6b',fmt='csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = qc.mydb_import ('objects6c', ps1_url, verbose=True)               # Load from service URL directly\n",
    "print ('Num rows in objects6c: ' + qc.query('select count(*) from mydb://objects6c',fmt='csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for each of the tables created, the column names and data types were determined automatically.  We can check whether these are correct by listing the columns using *mydb_list()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (qc.mydb_list('objects4'))              # Use of the 'mydb://' prefix is optional\n",
    "print (qc.mydb_list('mydb://objects6a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Piecewise Loading of MyDB Tables\n",
    "\n",
    "Importing data to MyDB requires two basic steps:  1) Creating the table in the database, and 2) loading the data.  The *mydb_import()* method combines these steps as a convenience but provides additional functionality to automatically convert data formats and derive the table schema.  If you should need to override these steps for some reason, each step can be done individually.\n",
    "\n",
    "### Create the MyDB table\n",
    "Creating an empty MyDB table is done with the *mydb_create()* method:\n",
    "\n",
    "    result = queryClient.mydb_create ([token], <table_name>, <schema_def>)\n",
    "where\n",
    "\n",
    "    token         login token (optional)\n",
    "    table_name    name of the MyDB table to create\n",
    "    schema_def    filename containing a schema definition, or a string containing the schema definition\n",
    "    drop          [Optional, default=True] Drop any existing table before loading the new one.\n",
    "    \n",
    "The *mydb_create()* step needs a table name (needs to not duplicate an existing myDB table) and a schema definition.  The schema definition is stored in a text file, in this case in the user notebook directory. The schema definition file is a CSV-formatted file that contains column name and (Postgres) data type, one row per column. The token here is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a simple (id,ra,dec) schema of a text string and two double values\n",
    "schema_str = 'id,text\\nra,double precision\\ndec,double precision\\n'\n",
    "with open ('schema.txt','w') as fd:\n",
    "    fd.write (schema_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1:  Create a table from a schema definition file, drop existing table\n",
    "print(\"Creating table 'test'... \",qc.mydb_create('test1','schema.txt',drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2:  Create a table from a schema definition str\n",
    "print(\"Creating table 'test'... \",qc.mydb_create('test2', schema_str, drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"table1 structure:\\n\" + qc.mydb_list('test1'))\n",
    "print(\"table2 structure:\\n\" + qc.mydb_list('test2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert data \n",
    "Loading a MyDB table with data is done with the *mydb_insert()* method:\n",
    "\n",
    "    result = queryClient.mydb_insert ([token], <table_name>, <data>)\n",
    "where\n",
    "\n",
    "    token         login token (optional)\n",
    "    table_name    name of the MyDB table to load\n",
    "    data          filename of CSV data or a CSV string\n",
    "    csv_header    [Optional, default=True] CSV data contains a header row of column names\n",
    "    \n",
    "Insert the data from a file/string in user's notebook space to the newly created table in myDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1:  Load from a CSV file\n",
    "print('Loading from file:   ' + qc.mydb_insert('test1', 'objects.csv'))\n",
    "\n",
    "# Example 2: Load from a CSV string\n",
    "print('Loading from string: ' + qc.mydb_insert('test2', data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data from myDB table to verify\n",
    "You can use queryClient to query tables in mydb, exactly as you would for Data Lab database tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running query: 'select * from mydb://test1'\")\n",
    "df1=convert(qc.query(sql=\"select * from mydb://test1\"))\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"crossmatch\"></a>\n",
    "## Run the crossmatch\n",
    "We now construct a query to run the crossmatch in the database using *q3c_join()*, which identifies all matching objects within a specified radius. (See https://github.com/segasai/q3c for details on using Q3C functions.)  The format is \n",
    "\n",
    "        q3c_join (ra_user, dec_user, ra_DLtable, dec_DLtable, radius) \n",
    "where it's important that the small user catalog appear FIRST in the query, and the large table from Data Lab database SECOND. The radius is specified in DEGREES.  The user table is referred to using a *mydb://* prefix on the table name. In this example, we parse the result into a Pandas dataframe with the DL helpers module *convert()*.  In the query, we retrieve just the user ID and the object designation from Gaia DR2 along with the separating distance by using the *q3c_dist()* function (and convert the return value in degrees to arcsec).\n",
    "\n",
    "If you find your q3c_join query runs a long time, check:\n",
    "* That the ra, dec of the SMALL catalog appears FIRST in the query\n",
    "* That the radius is in DEGREES, not e.g. arcseconds\n",
    "\n",
    "(Note that in this notebook, we use a radius of 0.01 degrees or ~36 arcseconds.  It's usually best to start with a smaller radius, especially if you expect a lot of matches.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# xmatch query of mydb://objects6a (our small PS1 table) against gaia_dr2.gaia_source within 0.01 degrees, return all matches\n",
    "sql = '''SELECT  o.objid, g.designation,\n",
    "                (q3c_dist(o.ramean,o.decmean,g.ra,g.dec)*3600.0) as dist_arcsec\n",
    "         FROM mydb://objects6a AS o, \n",
    "              gaia_dr2.gaia_source AS g \n",
    "         WHERE q3c_join(o.ramean, o.decmean, g.ra, g.dec, 0.01)'''\n",
    "df2 = convert(qc.query(sql=sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('nrows x ncols: ' + str(df2.shape))\n",
    "df2[0:10] # first 10 rows, note multiple matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note again that this query returns *__all__* matches within the radius for each object in list.  The crossmatch query can be written to other result tables such as only the nearest neighbor, only those objects in the user table that have matches, non-matches (i.e. objects with no match the find catalog dropouts), or it can be used to pre-filter either table (e.g. only match 'red' objects with a stellar profile).  The Q3C documentation (see https://github.com/segasai/q3c) contains additional example queries you can try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Want to do just a nearest neighbor search?__  This example adapted from the Q3C documentation picks just the nearest neighbor, returning null if none are found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sql = '''SELECT  o.objid, gg.designation, (q3c_dist(o.ramean,o.decmean,gg.ra,gg.dec)*3600.0) as dist_arcsec \n",
    "         FROM mydb://objects6a AS o\n",
    "         LEFT JOIN LATERAL (\n",
    "               SELECT g.* \n",
    "                    FROM \n",
    "                        gaia_dr2.gaia_source AS g\n",
    "                    WHERE\n",
    "                        q3c_join(o.ramean, o.decmean, g.ra, g.dec, 0.01)\n",
    "                    ORDER BY\n",
    "                        q3c_dist(o.ramean,o.decmean,g.ra,g.dec)\n",
    "                    ASC LIMIT 1\n",
    "               ) as gg ON true;'''\n",
    "\n",
    "df3 = convert(qc.query(sql=sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('nrows x ncols: ' + str(df3.shape))\n",
    "df3[0:10] # first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Don't want the non-matching rows?__  Just replace the LEFT JOIN above with an INNER JOIN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sql = '''SELECT  o.objid, gg.designation, (q3c_dist(o.ramean,o.decmean,gg.ra,gg.dec)*3600.0) as dist_arcsec \n",
    "         FROM mydb://objects6a AS o\n",
    "         INNER JOIN LATERAL (\n",
    "               SELECT g.* \n",
    "                    FROM \n",
    "                        gaia_dr2.gaia_source AS g\n",
    "                    WHERE\n",
    "                        q3c_join(o.ramean, o.decmean, g.ra, g.dec, 0.01)\n",
    "                    ORDER BY\n",
    "                        q3c_dist(o.ramean,o.decmean,g.ra,g.dec)\n",
    "                    ASC LIMIT 1\n",
    "               ) as gg ON true;'''\n",
    "\n",
    "df4 = convert(qc.query(sql=sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('nrows x ncols: ' + str(df4.shape))\n",
    "df4[0:10] # first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "If the myDB table was meant to be temporary, it can be dropped with *mydb_drop()*.  Here, we'll drop only the tables created in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop any tables or temp files we created.\n",
    "if do_cleanup:\n",
    "    for table in ['test1','test2','objects1','objects2','objects3','objects4','objects5','objects6a','objects6b','objects6c']:\n",
    "        print(\"Dropping table '\" + table + \"' ... \\t\" + qc.mydb_drop(table))\n",
    "    print(\"Listing mydb tables:\\n\" + qc.mydb_list())\n",
    "    \n",
    "    for f in ['objects.csv','schema.txt']:\n",
    "        if os.path.exists(f):\n",
    "            os.remove (f)\n",
    "    if sc.access ('vos://objects.csv'):\n",
    "        print ('removing objects.csv')\n",
    "        sc.rm ('vos://objects.csv')\n",
    "    if sc.access ('vos://objects.vot'):\n",
    "        print ('removing objects.vot')\n",
    "        sc.rm ('vos://objects.vot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead you want to drop __all__ tables in your MyDB, you can do this by processing the list, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:      # Change this to remove all tables\n",
    "    print(\"Initial listing of mydb tables:\\n\" + qc.mydb_list())\n",
    "    table_list = qc.list().split('\\n')    # convert string return to array\n",
    "    for table in table_list:\n",
    "        print(\"Dropping table '\" + table + \"' ... \\t\" + qc.mydb_drop(table))\n",
    "    print(\"\\nFinal listing of mydb tables:\\n\" + qc.mydb_list())\n",
    "    print(\"\\nFinal list of VOSpace:\\n\" + sc.ls(format='long'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
